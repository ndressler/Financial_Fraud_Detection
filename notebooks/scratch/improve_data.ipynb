{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this file is just a quick try to improve the models predictions on anomalies and normal instances but even with new and different data preprocessing methods, leaving or removing many features, the models behave the same at the end, either they can precisely predict normal instances with many FN or precisely predict anomalies but then also high FP and lower TN, so either the model can predict anomalies or normal instances \n",
    "\n",
    "even changing the threshold of the model came to the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries imported and used throught the code\n",
    "import pandas as pd\n",
    "import sklearn as sklearn\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions\n",
    "sys.path.insert(0, '../../')\n",
    "from src.functions import Data, Preprocessing\n",
    "\n",
    "dt = Data()\n",
    "prep = Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for  files\n",
    "data_dir = os.path.join(os.getcwd(), '../../data/raw/')\n",
    "\n",
    "# relative paths\n",
    "rel_path_train_tran = 'train_transaction.csv'\n",
    "rel_path_train_id = 'train_identity.csv'\n",
    "\n",
    "# absolute paths\n",
    "abs_path_train_tran = os.path.join(data_dir, rel_path_train_tran)\n",
    "abs_path_train_id = os.path.join(data_dir, rel_path_train_id)\n",
    "\n",
    "# read files\n",
    "train_tran = pd.read_csv(abs_path_train_tran)\n",
    "train_id = pd.read_csv(abs_path_train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge  files\n",
    "train = pd.merge(train_tran, train_id, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop target feature\n",
    "y = train.pop('isFraud')\n",
    "X = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns containing 75% or more of values missing\n",
    "missing_values_train = (X.isnull().sum() / len(X)) * 100\n",
    "columns_to_drop_train = missing_values_train[missing_values_train >= 50].index\n",
    "X = X.drop(columns=columns_to_drop_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Columns: 219 entries, TransactionID to V321\n",
      "dtypes: float64(207), int64(3), object(9)\n",
      "memory usage: 986.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save columns\n",
    "X_cols = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace inf and -inf with NaN\n",
    "X = X.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>V312</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.00</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.00</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.00</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590535</th>\n",
       "      <td>3577535</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.00</td>\n",
       "      <td>W</td>\n",
       "      <td>6550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590536</th>\n",
       "      <td>3577536</td>\n",
       "      <td>15811049</td>\n",
       "      <td>39.50</td>\n",
       "      <td>W</td>\n",
       "      <td>10444</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590537</th>\n",
       "      <td>3577537</td>\n",
       "      <td>15811079</td>\n",
       "      <td>30.95</td>\n",
       "      <td>W</td>\n",
       "      <td>12037</td>\n",
       "      <td>595.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590538</th>\n",
       "      <td>3577538</td>\n",
       "      <td>15811088</td>\n",
       "      <td>117.00</td>\n",
       "      <td>W</td>\n",
       "      <td>7826</td>\n",
       "      <td>481.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>317.500000</td>\n",
       "      <td>669.500000</td>\n",
       "      <td>317.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590539</th>\n",
       "      <td>3577539</td>\n",
       "      <td>15811131</td>\n",
       "      <td>279.95</td>\n",
       "      <td>W</td>\n",
       "      <td>15066</td>\n",
       "      <td>170.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.950012</td>\n",
       "      <td>279.950012</td>\n",
       "      <td>279.950012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
       "0             2987000          86400           68.50         W  13926    NaN   \n",
       "1             2987001          86401           29.00         W   2755  404.0   \n",
       "2             2987002          86469           59.00         W   4663  490.0   \n",
       "3             2987003          86499           50.00         W  18132  567.0   \n",
       "4             2987004          86506           50.00         H   4497  514.0   \n",
       "...               ...            ...             ...       ...    ...    ...   \n",
       "590535        3577535       15811047           49.00         W   6550    NaN   \n",
       "590536        3577536       15811049           39.50         W  10444  225.0   \n",
       "590537        3577537       15811079           30.95         W  12037  595.0   \n",
       "590538        3577538       15811088          117.00         W   7826  481.0   \n",
       "590539        3577539       15811131          279.95         W  15066  170.0   \n",
       "\n",
       "        card3       card4  card5   card6  ...   V312        V313        V314  \\\n",
       "0       150.0    discover  142.0  credit  ...    0.0    0.000000    0.000000   \n",
       "1       150.0  mastercard  102.0  credit  ...    0.0    0.000000    0.000000   \n",
       "2       150.0        visa  166.0   debit  ...    0.0    0.000000    0.000000   \n",
       "3       150.0  mastercard  117.0   debit  ...  135.0    0.000000    0.000000   \n",
       "4       150.0  mastercard  102.0  credit  ...    0.0    0.000000    0.000000   \n",
       "...       ...         ...    ...     ...  ...    ...         ...         ...   \n",
       "590535  150.0        visa  226.0   debit  ...    0.0   47.950001   47.950001   \n",
       "590536  150.0  mastercard  224.0   debit  ...    0.0    0.000000    0.000000   \n",
       "590537  150.0  mastercard  224.0   debit  ...    0.0    0.000000    0.000000   \n",
       "590538  150.0  mastercard  224.0   debit  ...  117.0  317.500000  669.500000   \n",
       "590539  150.0  mastercard  102.0  credit  ...    0.0    0.000000    0.000000   \n",
       "\n",
       "              V315  V316    V317   V318        V319        V320        V321  \n",
       "0         0.000000   0.0   117.0    0.0    0.000000    0.000000    0.000000  \n",
       "1         0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "2         0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "3         0.000000  50.0  1404.0  790.0    0.000000    0.000000    0.000000  \n",
       "4         0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "...            ...   ...     ...    ...         ...         ...         ...  \n",
       "590535   47.950001   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "590536    0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "590537    0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "590538  317.500000   0.0  2234.0    0.0    0.000000    0.000000    0.000000  \n",
       "590539    0.000000   0.0     0.0    0.0  279.950012  279.950012  279.950012  \n",
       "\n",
       "[590540 rows x 219 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install category_encoders\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "# for hig dimension data\n",
    "\n",
    "# Binary Encoding\n",
    "binary_encoder = BinaryEncoder()\n",
    "X_train_binary_encoded = binary_encoder.fit_transform(X.select_dtypes(include=['object']))\n",
    "# Drop the original categorical columns\n",
    "X_num = X.drop(columns=X.select_dtypes(include=['object']).columns)\n",
    "# Concatenate the binary-encoded DataFrame with the remaining columns\n",
    "X_bin = pd.concat([X_num, X_train_binary_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>C1</th>\n",
       "      <th>...</th>\n",
       "      <th>M1_1</th>\n",
       "      <th>M2_0</th>\n",
       "      <th>M2_1</th>\n",
       "      <th>M3_0</th>\n",
       "      <th>M3_1</th>\n",
       "      <th>M4_0</th>\n",
       "      <th>M4_1</th>\n",
       "      <th>M4_2</th>\n",
       "      <th>M6_0</th>\n",
       "      <th>M6_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.00</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.00</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.00</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590535</th>\n",
       "      <td>3577535</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.00</td>\n",
       "      <td>6550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590536</th>\n",
       "      <td>3577536</td>\n",
       "      <td>15811049</td>\n",
       "      <td>39.50</td>\n",
       "      <td>10444</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590537</th>\n",
       "      <td>3577537</td>\n",
       "      <td>15811079</td>\n",
       "      <td>30.95</td>\n",
       "      <td>12037</td>\n",
       "      <td>595.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590538</th>\n",
       "      <td>3577538</td>\n",
       "      <td>15811088</td>\n",
       "      <td>117.00</td>\n",
       "      <td>7826</td>\n",
       "      <td>481.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590539</th>\n",
       "      <td>3577539</td>\n",
       "      <td>15811131</td>\n",
       "      <td>279.95</td>\n",
       "      <td>15066</td>\n",
       "      <td>170.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  TransactionDT  TransactionAmt  card1  card2  card3  \\\n",
       "0             2987000          86400           68.50  13926    NaN  150.0   \n",
       "1             2987001          86401           29.00   2755  404.0  150.0   \n",
       "2             2987002          86469           59.00   4663  490.0  150.0   \n",
       "3             2987003          86499           50.00  18132  567.0  150.0   \n",
       "4             2987004          86506           50.00   4497  514.0  150.0   \n",
       "...               ...            ...             ...    ...    ...    ...   \n",
       "590535        3577535       15811047           49.00   6550    NaN  150.0   \n",
       "590536        3577536       15811049           39.50  10444  225.0  150.0   \n",
       "590537        3577537       15811079           30.95  12037  595.0  150.0   \n",
       "590538        3577538       15811088          117.00   7826  481.0  150.0   \n",
       "590539        3577539       15811131          279.95  15066  170.0  150.0   \n",
       "\n",
       "        card5  addr1  addr2   C1  ...  M1_1  M2_0  M2_1  M3_0  M3_1  M4_0  \\\n",
       "0       142.0  315.0   87.0  1.0  ...     1     0     1     0     1     0   \n",
       "1       102.0  325.0   87.0  1.0  ...     1     1     1     1     1     0   \n",
       "2       166.0  330.0   87.0  1.0  ...     1     0     1     0     1     0   \n",
       "3       117.0  476.0   87.0  2.0  ...     1     1     1     1     1     0   \n",
       "4       102.0  420.0   87.0  1.0  ...     1     1     1     1     1     1   \n",
       "...       ...    ...    ...  ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "590535  226.0  272.0   87.0  2.0  ...     1     0     1     0     1     0   \n",
       "590536  224.0  204.0   87.0  1.0  ...     1     1     0     1     0     0   \n",
       "590537  224.0  231.0   87.0  1.0  ...     1     1     0     1     0     1   \n",
       "590538  224.0  387.0   87.0  1.0  ...     1     0     1     0     1     0   \n",
       "590539  102.0  299.0   87.0  2.0  ...     1     1     0     1     0     1   \n",
       "\n",
       "        M4_1  M4_2  M6_0  M6_1  \n",
       "0          0     1     0     1  \n",
       "1          1     0     0     1  \n",
       "2          1     0     1     0  \n",
       "3          1     0     1     0  \n",
       "4          0     0     1     1  \n",
       "...      ...   ...   ...   ...  \n",
       "590535     1     0     1     0  \n",
       "590536     1     0     0     1  \n",
       "590537     0     0     0     1  \n",
       "590538     1     0     0     1  \n",
       "590539     0     0     0     1  \n",
       "\n",
       "[590540 rows x 236 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "simple_imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_simp_bin = simple_imputer.fit_transform(X_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For anomaly detection algorithms like Isolation Forest, Local Outlier Factor (LOF), and One-Class SVM (OCSVM), it's generally a good practice to scale your data because these algorithms are distance-based and can be sensitive to the scale of the features.\n",
    "\n",
    "StandardScaler is a common choice as it scales the features to have mean=0 and variance=1, which ensures that all features have the same scale. However, if you have outliers in your data, which is likely in financial fraud data, StandardScaler might not be the best choice because it's sensitive to outliers.\n",
    "\n",
    "In this case, you might want to use a robust scaler such as RobustScaler in scikit-learn. RobustScaler scales the data according to the quantile range, making it robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Create a RobustScaler object\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Fit the RobustScaler to the data and transform the data\n",
    "X_simp_bin_robust = robust_scaler.fit_transform(X_simp_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data back to dataframes\n",
    "X_df = pd.DataFrame(X_simp_bin_robust, columns=X_bin.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features:  236\n",
      "Number of features after variance threshold:  123\n",
      "Number of features removed:  113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Define the selector\n",
    "selector = VarianceThreshold(threshold=1)\n",
    "\n",
    "# Determine the number of chunks\n",
    "chunk_size = 10000\n",
    "num_chunks = int(np.ceil(X_df.shape[0] / chunk_size))\n",
    "\n",
    "# Initialize an empty list to hold the selected features\n",
    "selected_features = []\n",
    "\n",
    "# Process each chunk\n",
    "for i in range(num_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = min((i + 1) * chunk_size, X_df.shape[0])\n",
    "    X_chunk = X_df.iloc[start:end, :]\n",
    "\n",
    "    # Fit the selector to the chunk\n",
    "    X_fs = selector.fit_transform(X_chunk)\n",
    "\n",
    "    # Get the selected features for this chunk\n",
    "    chunk_selected_features = X_chunk.columns[selector.get_support(indices=True)]\n",
    "\n",
    "    # Add the selected features to the list\n",
    "    selected_features.extend(chunk_selected_features)\n",
    "\n",
    "# Remove duplicates from the list of selected features\n",
    "selected_features = list(set(selected_features))\n",
    "\n",
    "# Print the number of features\n",
    "print(\"Original number of features: \", X_df.shape[1])\n",
    "print(\"Number of features after variance threshold: \", len(selected_features))\n",
    "print(\"Number of features removed: \", X_df.shape[1] - len(selected_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols = X_new.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 1 to -1 and 0 to 1\n",
    "y = y.map(lambda i: -1 if i == 1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a temporary training set and a test set\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# split the temporary training set into a final training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# convert arrays back to DataFrames\n",
    "X_train = pd.DataFrame(X_train, columns=xcols)\n",
    "X_val = pd.DataFrame(X_val, columns=xcols)\n",
    "X_test = pd.DataFrame(X_test, columns=xcols)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns=['isFraud'])\n",
    "y_val = pd.DataFrame(y_val, columns=['isFraud'])\n",
    "y_test = pd.DataFrame(y_test, columns=['isFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import sys, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../../')\n",
    "from src.functions import Data, Modeling, Evaluation\n",
    "\n",
    "dt = Data()\n",
    "mod = Modeling()\n",
    "eval = Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save column names\n",
    "X_val_df = X_val\n",
    "\n",
    "# Convert pandas dataframes to numpy arrays for memory efficiency\n",
    "X_train = X_train.values\n",
    "X_val = X_val.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "bm = IsolationForest(contamination=0.01, n_jobs=-1, random_state=42)\n",
    "bm.fit(X_train)\n",
    "bm_pred = bm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model Base Model - Isolation Forest:\n",
      "\n",
      "True Positives: 161\n",
      "True Negatives: 112953\n",
      "False Positives: 1022\n",
      "False Negatives: 3972\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bm_cm = eval.get_cm(bm_pred, y_val)\n",
    "eval.cm_inf(bm_cm, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Base Model - Isolation Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.14      0.04      0.06      4133\n",
      "           1       0.97      0.99      0.98    113975\n",
      "\n",
      "    accuracy                           0.96    118108\n",
      "   macro avg       0.55      0.51      0.52    118108\n",
      "weighted avg       0.94      0.96      0.95    118108\n",
      "\n",
      "\n",
      "\n",
      "Metrics of Base Model - Isolation Forest:\n",
      "\n",
      "Recall: 0.039\n",
      "Precision: 0.1361\n",
      "F1 Score: 0.0606\n",
      "PR AUC: 0.0389\n",
      "AU ROC: 0.515\n",
      "Specificity: 0.991\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "eval.print_classreport(y_val, bm_pred, 'Base Model - Isolation Forest')\n",
    "\n",
    "bm_metrics = eval.get_metrics(bm_cm, y_val, bm_pred)\n",
    "eval.print_metrics(bm_metrics, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "# Initialize the model\n",
    "bm = LocalOutlierFactor(n_neighbors=20, contamination=0.1, novelty=True)\n",
    "bm.fit(X_train)\n",
    "bm_pred = bm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model Base Model - Isolation Forest:\n",
      "\n",
      "True Positives: 590\n",
      "True Negatives: 102880\n",
      "False Positives: 11095\n",
      "False Negatives: 3543\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bm_cm = eval.get_cm(bm_pred, y_val)\n",
    "eval.cm_inf(bm_cm, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Base Model - Isolation Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.05      0.14      0.07      4133\n",
      "           1       0.97      0.90      0.93    113975\n",
      "\n",
      "    accuracy                           0.88    118108\n",
      "   macro avg       0.51      0.52      0.50    118108\n",
      "weighted avg       0.93      0.88      0.90    118108\n",
      "\n",
      "\n",
      "\n",
      "Metrics of Base Model - Isolation Forest:\n",
      "\n",
      "Recall: 0.1428\n",
      "Precision: 0.0505\n",
      "F1 Score: 0.0746\n",
      "PR AUC: 0.0372\n",
      "AU ROC: 0.5227\n",
      "Specificity: 0.9027\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "eval.print_classreport(y_val, bm_pred, 'Base Model - Isolation Forest')\n",
    "\n",
    "bm_metrics = eval.get_metrics(bm_cm, y_val, bm_pred)\n",
    "eval.print_metrics(bm_metrics, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial_fraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
