{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../../')\n",
    "from src.functions import Data, Modeling, Evaluation\n",
    "\n",
    "dt = Data()\n",
    "mod = Modeling()\n",
    "eval = Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data directory\n",
    "data_dir = os.path.join(os.getcwd(), '../../data/processed')\n",
    "\n",
    "\n",
    "# relative paths\n",
    "rel_path_X_train = 'X_train.pkl'\n",
    "rel_path_X_val = 'X_val.pkl'\n",
    "rel_path_X_test = 'X_test.pkl'\n",
    "rel_path_y_train = 'y_train.pkl'\n",
    "rel_path_y_val = 'y_val.pkl'\n",
    "rel_path_y_test = 'y_test.pkl'\n",
    "\n",
    "# absolute paths\n",
    "abs_path_X_train = os.path.join(data_dir, rel_path_X_train)\n",
    "abs_path_X_val = os.path.join(data_dir, rel_path_X_val)\n",
    "abs_path_X_test = os.path.join(data_dir, rel_path_X_test)\n",
    "abs_path_y_train = os.path.join(data_dir, rel_path_y_train)\n",
    "abs_path_y_val = os.path.join(data_dir, rel_path_y_val)\n",
    "abs_path_y_test = os.path.join(data_dir, rel_path_y_test)\n",
    "\n",
    "# read files\n",
    "X_train = pd.read_pickle(abs_path_X_train)\n",
    "X_val = pd.read_pickle(abs_path_X_val)\n",
    "X_test = pd.read_pickle(abs_path_X_test)\n",
    "y_train = pd.read_pickle(abs_path_y_train)\n",
    "y_val = pd.read_pickle(abs_path_y_val)\n",
    "y_test = pd.read_pickle(abs_path_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save column names\n",
    "X_val_df = X_val\n",
    "\n",
    "# Convert pandas dataframes to numpy arrays for memory efficiency\n",
    "X_train = X_train.values\n",
    "X_val = X_val.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "bm = LocalOutlierFactor(n_neighbors=35,\n",
    "                        contamination=0.05, # Lower contamination to make the model more conservative in predicting anomalies\n",
    "                        novelty=True,\n",
    "                        algorithm='auto',\n",
    "                        leaf_size=50,\n",
    "                        metric='minkowski',\n",
    "                        p=3)\n",
    "bm.fit(X_train)\n",
    "bm_pred = bm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model LOF:\n",
      "\n",
      "True Positives: 402\n",
      "True Negatives: 108528\n",
      "False Positives: 5447\n",
      "False Negatives: 3731\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bm_cm = eval.get_cm(bm_pred, y_val)\n",
    "eval.cm_inf(bm_cm, 'LOF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "bm = IsolationForest(contamination=0.001, # Lower contamination makes the model more conservative in classifying instances as anomalies\n",
    "                     n_jobs=-1,\n",
    "                     random_state=42,\n",
    "                     n_estimators=2000, # Increase the number of base estimators\n",
    "                     max_samples=1.0, # Use all samples for training each base estimator\n",
    "                     max_features=1.0, # Use all features for training each base estimator\n",
    "                     bootstrap=True)\n",
    "bm.fit(X_train)\n",
    "bm_pred = bm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6168985779915752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the threshold used by the predict method\n",
    "threshold = bm.offset_\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model Base Model - Isolation Forest:\n",
      "\n",
      "True Positives: 7\n",
      "True Negatives: 113856\n",
      "False Positives: 119\n",
      "False Negatives: 4126\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bm_cm = eval.get_cm(bm_pred, y_val)\n",
    "eval.cm_inf(bm_cm, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       ...,\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal instances: 113975\n",
      "Number of anomalies: 4133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Flatten y_val to 1D array\n",
    "y_val_flat = y_val.flatten()\n",
    "\n",
    "# Count the number of normal instances (1) and anomalies (-1)\n",
    "normal_count = np.sum(y_val_flat == 1)\n",
    "anomaly_count = np.sum(y_val_flat == -1)\n",
    "\n",
    "print(f'Number of normal instances: {normal_count}')\n",
    "print(f'Number of anomalies: {anomaly_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Initialize the model\n",
    "bm = IsolationForest(contamination=0.01, n_jobs=-1, random_state=42)\n",
    "bm.fit(X_train)\n",
    "\n",
    "# Get the anomaly scores\n",
    "scores = bm.decision_function(X_val)\n",
    "\n",
    "# Set the threshold\n",
    "threshold = 0.1\n",
    "\n",
    "# Convert scores into class predictions\n",
    "bm_pred = (scores <= threshold).astype('int')\n",
    "\n",
    "# Convert the -1/1 anomaly labels to 0/1\n",
    "bm_pred = ((bm_pred + 1) / 2).astype('int')\n",
    "y_val = ((y_val + 1) / 2).astype('int')\n",
    "\n",
    "# Get the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, bm_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 3658   475]\n",
      " [96191 17784]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_val and bm_pred are your true and predicted labels respectively\n",
    "cm = confusion_matrix(y_val, bm_pred)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model Base Model - Isolation Forest:\n",
      "\n",
      "True Positives: 1654\n",
      "True Negatives: 56674\n",
      "False Positives: 57301\n",
      "False Negatives: 2479\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model with a lower contamination parameter\n",
    "bm = IsolationForest(contamination=0.5, n_jobs=-1, random_state=42)\n",
    "bm.fit(X_train)\n",
    "\n",
    "bm_pred = bm.predict(X_val)\n",
    "\n",
    "bm_cm = eval.get_cm(bm_pred, y_val)\n",
    "eval.cm_inf(bm_cm, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4561186085728175"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the threshold used by the predict method\n",
    "threshold = bm.offset_\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 3658   475]\n",
      " [96191 17784]]\n"
     ]
    }
   ],
   "source": [
    "# Set a higher threshold\n",
    "threshold = 0.1\n",
    "\n",
    "# Convert scores into class predictions\n",
    "bm_pred = (scores <= threshold).astype('int')\n",
    "\n",
    "# Convert the -1/1 anomaly labels to 0/1\n",
    "bm_pred = ((bm_pred + 1) / 2).astype('int')\n",
    "\n",
    "# Get the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, bm_pred).ravel()\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_val, bm_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1400656058.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[67], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    [[TN FP]\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "[[TN FP]\n",
    " [FN TP]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal, normal predicted anomaly\n",
    "anomaly predicted normal, anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted anomaly scores\n",
    "scores_pred = bm.decision_function(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model Base Model - Isolation Forest:\n",
      "\n",
      "True Positives: 1894\n",
      "True Negatives: 53730\n",
      "False Positives: 60245\n",
      "False Negatives: 2239\n",
      "\n",
      "\n",
      "Classification Report for Base Model - Isolation Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.03      0.46      0.06      4133\n",
      "           1       0.96      0.47      0.63    113975\n",
      "\n",
      "    accuracy                           0.47    118108\n",
      "   macro avg       0.50      0.46      0.34    118108\n",
      "weighted avg       0.93      0.47      0.61    118108\n",
      "\n",
      "\n",
      "\n",
      "Metrics of Base Model - Isolation Forest:\n",
      "\n",
      "Recall: 0.4583\n",
      "Precision: 0.0305\n",
      "F1 Score: 0.0572\n",
      "PR AUC: 0.0329\n",
      "AU ROC: 0.4648\n",
      "Specificity: 0.4714\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, scores_pred)\n",
    "\n",
    "# Compute the Euclidean distance from each point on the ROC curve to the top left corner\n",
    "distances = np.sqrt((1 - tpr) ** 2 + fpr ** 2)\n",
    "\n",
    "# Find the index of the point with the minimum distance\n",
    "min_index = np.argmin(distances)\n",
    "\n",
    "# Get the threshold corresponding to this point\n",
    "optimal_threshold = thresholds[min_index]\n",
    "\n",
    "# Apply the optimal threshold to the anomaly scores to get the final predictions\n",
    "bm_pred_hilfe = np.where(scores_pred <= optimal_threshold, -1, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "bm_cm_hilfe = eval.get_cm(bm_pred_hilfe, y_val)\n",
    "eval.cm_inf(bm_cm_hilfe, 'Base Model - Isolation Forest')\n",
    "\n",
    "# Print the classification report\n",
    "eval.print_classreport(y_val, bm_pred_hilfe, 'Base Model - Isolation Forest')\n",
    "\n",
    "bm_metrics = eval.get_metrics(bm_cm_hilfe, y_val, bm_pred_hilfe)\n",
    "eval.print_metrics(bm_metrics, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       " 1         0.965007\n",
       "-1         0.034993\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply ADASYN\n",
    "ad = ADASYN(random_state=42)\n",
    "X_train_res_adasyn, y_train_res_adasyn = ad.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 354324 entries, 32965 to 587621\n",
      "Data columns (total 37 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   D15_to_std_card1              354324 non-null  float64\n",
      " 1   D15_to_mean_card1             354324 non-null  float64\n",
      " 2   D15_to_std_card4              354324 non-null  float64\n",
      " 3   card2                         354324 non-null  float64\n",
      " 4   TransactionAmt_to_std_addr1   354324 non-null  float64\n",
      " 5   TransactionAmt_to_mean_addr2  354324 non-null  float64\n",
      " 6   D11                           354324 non-null  float64\n",
      " 7   D2                            354324 non-null  float64\n",
      " 8   M4                            354324 non-null  float64\n",
      " 9   M1                            354324 non-null  float64\n",
      " 10  TransactionAmt_to_mean_addr1  354324 non-null  float64\n",
      " 11  D1                            354324 non-null  float64\n",
      " 12  M7                            354324 non-null  float64\n",
      " 13  ProductCD                     354324 non-null  float64\n",
      " 14  M3                            354324 non-null  float64\n",
      " 15  M6                            354324 non-null  float64\n",
      " 16  TransactionAmt_to_mean_card1  354324 non-null  float64\n",
      " 17  card4                         354324 non-null  float64\n",
      " 18  card5                         354324 non-null  float64\n",
      " 19  D15_to_mean_card4             354324 non-null  float64\n",
      " 20  D15_to_std_addr2              354324 non-null  float64\n",
      " 21  M2                            354324 non-null  float64\n",
      " 22  TransactionAmt_to_std_card4   354324 non-null  float64\n",
      " 23  TransactionAmt_to_mean_card4  354324 non-null  float64\n",
      " 24  M5                            354324 non-null  float64\n",
      " 25  D15_to_std_addr1              354324 non-null  float64\n",
      " 26  card1                         354324 non-null  float64\n",
      " 27  P_emaildomain                 354324 non-null  float64\n",
      " 28  D15                           354324 non-null  float64\n",
      " 29  D15_to_mean_addr1             354324 non-null  float64\n",
      " 30  M8                            354324 non-null  float64\n",
      " 31  TransactionAmt_to_std_addr2   354324 non-null  float64\n",
      " 32  D15_to_mean_addr2             354324 non-null  float64\n",
      " 33  addr1                         354324 non-null  float64\n",
      " 34  TransactionAmt_to_std_card1   354324 non-null  float64\n",
      " 35  D10                           354324 non-null  float64\n",
      " 36  M9                            354324 non-null  float64\n",
      "dtypes: float64(37)\n",
      "memory usage: 102.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 683854 entries, 0 to 683853\n",
      "Data columns (total 37 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   D15_to_std_card1              683854 non-null  float64\n",
      " 1   D15_to_mean_card1             683854 non-null  float64\n",
      " 2   D15_to_std_card4              683854 non-null  float64\n",
      " 3   card2                         683854 non-null  float64\n",
      " 4   TransactionAmt_to_std_addr1   683854 non-null  float64\n",
      " 5   TransactionAmt_to_mean_addr2  683854 non-null  float64\n",
      " 6   D11                           683854 non-null  float64\n",
      " 7   D2                            683854 non-null  float64\n",
      " 8   M4                            683854 non-null  float64\n",
      " 9   M1                            683854 non-null  float64\n",
      " 10  TransactionAmt_to_mean_addr1  683854 non-null  float64\n",
      " 11  D1                            683854 non-null  float64\n",
      " 12  M7                            683854 non-null  float64\n",
      " 13  ProductCD                     683854 non-null  float64\n",
      " 14  M3                            683854 non-null  float64\n",
      " 15  M6                            683854 non-null  float64\n",
      " 16  TransactionAmt_to_mean_card1  683854 non-null  float64\n",
      " 17  card4                         683854 non-null  float64\n",
      " 18  card5                         683854 non-null  float64\n",
      " 19  D15_to_mean_card4             683854 non-null  float64\n",
      " 20  D15_to_std_addr2              683854 non-null  float64\n",
      " 21  M2                            683854 non-null  float64\n",
      " 22  TransactionAmt_to_std_card4   683854 non-null  float64\n",
      " 23  TransactionAmt_to_mean_card4  683854 non-null  float64\n",
      " 24  M5                            683854 non-null  float64\n",
      " 25  D15_to_std_addr1              683854 non-null  float64\n",
      " 26  card1                         683854 non-null  float64\n",
      " 27  P_emaildomain                 683854 non-null  float64\n",
      " 28  D15                           683854 non-null  float64\n",
      " 29  D15_to_mean_addr1             683854 non-null  float64\n",
      " 30  M8                            683854 non-null  float64\n",
      " 31  TransactionAmt_to_std_addr2   683854 non-null  float64\n",
      " 32  D15_to_mean_addr2             683854 non-null  float64\n",
      " 33  addr1                         683854 non-null  float64\n",
      " 34  TransactionAmt_to_std_card1   683854 non-null  float64\n",
      " 35  D10                           683854 non-null  float64\n",
      " 36  M9                            683854 non-null  float64\n",
      "dtypes: float64(37)\n",
      "memory usage: 193.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118108"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model Base Model - Isolation Forest:\n",
      "\n",
      "True Positives: 43\n",
      "True Negatives: 112571\n",
      "False Positives: 1404\n",
      "False Negatives: 4090\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bm_cm = eval.get_cm(bm_pred, y_val)\n",
    "eval.cm_inf(bm_cm, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Base Model - Isolation Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.03      0.01      0.02      4133\n",
      "           1       0.96      0.99      0.98    113975\n",
      "\n",
      "    accuracy                           0.95    118108\n",
      "   macro avg       0.50      0.50      0.50    118108\n",
      "weighted avg       0.93      0.95      0.94    118108\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "eval.print_classreport(y_val, bm_pred, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of Base Model - Isolation Forest:\n",
      "\n",
      "Recall: 0.0104\n",
      "Precision: 0.0297\n",
      "F1 Score: 0.0154\n",
      "PR AUC: 0.0349\n",
      "AU ROC: 0.499\n",
      "Specificity: 0.9877\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bm_metrics = eval.get_metrics(bm_cm, y_val, bm_pred)\n",
    "eval.print_metrics(bm_metrics, 'Base Model - Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot a histogram for each feature in your dataset\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m:\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      7\u001b[0m     sns\u001b[38;5;241m.\u001b[39mhistplot(X_train[column], kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot a histogram for each feature in your dataset\n",
    "for column in X_train.columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(X_train[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial_fraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
